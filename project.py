# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tL5JtTJAE94sjOphkSKOBtrcjwyh5R_1
"""

! pip install pydicom

! wget https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.zip

!unzip 3Dircadb1.zip

! ls -lrth

! mkdir images1.1
! mkdir labels1.1

! unzip 3Dircadb1.1/PATIENT_DICOM.zip
! unzip 3Dircadb1.1/LABELLED_DICOM.zip

! mv PATIENT_DICOM/* images1.1/
! mv LABELLED_DICOM/* labels1.1/

file_names=['3Dircadb1.1','3Dircadb1.2','3Dircadb1.3','3Dircadb1.4','3Dircadb1.5','3Dircadb1.6','3Dircadb1.7','3Dircadb1.8','3Dircadb1.9','3Dircadb1.10','3Dircadb1.11','3Dircadb1.12','3Dircadb1.13','3Dircadb1.14','3Dircadb1.15','3Dircadb1.16','3Dircadb1.17','3Dircadb1.18','3Dircadb1.19','3Dircadb1.20']

! mkdir images1.1
! mkdir labels1.1
! unzip 3Dircadb1.1/PATIENT_DICOM.zip
! unzip 3Dircadb1./LABELLED_DICOM.zip
! mv PATIENT_DICOM/* images1.1/
! mv LABELLED_DICOM/* labels1.1/

import pydicom as dicom
import matplotlib.pylab as plt
import numpy as np
import os
# specify your image path
image_path = 'images1.2/image_0'
ds = dicom.dcmread(image_path)

plt.figure(figsize=(30,30))
plt.subplot(5,5,1)
plt.title('Input image',fontsize=20)

plt.imshow(ds.pixel_array)

plt.subplot(5,5,2)
image_path = 'labels1.2/image_0'
ds_2 = dicom.dcmread(image_path)
plt.title('Segmented image',fontsize=20)
plt.imshow(ds_2.pixel_array)

# Convert pixel_array (img) to -> gray image (img_2d_scaled)
## Step 1. Convert to float to avoid overflow or underflow losses.
ds_2=ds.pixel_array
img_2d = ds_2.astype(float)
# img_rgb=img_2d.reshape([img_2d.shape[1], img_2d.shape[2], 3])
# print(img_rgb.shape)


## Step 2. Rescaling grey scale between 0-255
img_2d_scaled = (np.maximum(img_2d,0) / img_2d.max()) * 255.0

## Step 3. Convert to uint
# img_2d_scaled = np.uint8(img_2d_scaled)

# img_gray=img_2d_scaled.reshape(512,512,1)

plt.imshow(img_2d_scaled)
print(img_2d_scaled)


'''
# Show information of input and output in above code
## (1) Show information of original CT image 
print(ds_2.dtype)
print(ds_2.shape)
print(ds_2)

## (2) Show information of gray image of it 
print(img_2d_scaled.dtype)
# print(img_gray.shape)
print(img_2d_scaled)

## (3) Show the scaled gray image by matplotlib
plt.imshow(img_2d_scaled, cmap='gray', vmin=0, vmax=255)
plt.show() '''

!ls -lrth

data=[]
labels=[]

img_path='images1.2/'
labels_path='labels1.2/'
img_size=128
import cv2
for file_name in sorted(os.listdir(img_path)):
  dc= dicom.dcmread(os.path.join(img_path,file_name))
  dc_arr=dc.pixel_array
  img_2d = dc_arr.astype(float)

  ## Step 2. Rescaling grey scale between 0-255
  img_2d_scaled = (np.maximum(img_2d,0) / img_2d.max()) * 255.0

  ## Step 3. Convert to uint
  img_2d_scaled = np.uint8(img_2d_scaled)
  img_2d_cv=cv2.resize(img_2d_scaled,(img_size,img_size))
  data.append(img_2d_cv)

  # labels converting into arrays
for label_name in sorted(os.listdir(labels_path)):
  dc= dicom.dcmread(os.path.join(labels_path,label_name))
  dc_arr=dc.pixel_array
  img_2d = dc_arr.astype(float)

  ## Step 2. Rescaling grey scale between 0-255
  img_2d_scaled = (np.maximum(img_2d,0) / img_2d.max()) * 255.0

  ## Step 3. Convert to uint
  img_2d_scaled = np.uint8(img_2d_scaled)
  img_2d_cv=cv2.resize(img_2d_scaled,(img_size,img_size))
  labels.append(img_2d_cv)

len(labels)



img_data=np.array(data)
labels_data=np.array(labels)
img_data.shape

img_data=img_data/255.0
img_data=img_data.reshape(-1,img_size,img_size,1)
labels_data=labels_data/255.0
labels_data=labels_data.reshape(-1,img_size,img_size,1)
print(f'img shape is {img_data.shape} labels shape is {labels_data.shape}')

np.save('img_data.npy',img_data)
np.save('labels_data.npy',labels_data)

!ls -lrth

!ls -lrth

import numpy as np
img_data=np.load('img_data.npy')
labels_data=np.load('labels_data.npy')
print(f'img shape is {img_data.shape} labels shape is {labels_data.shape}')

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(img_data,labels_data,test_size=0.2,random_state=42)
print(f' X_train size is {X_train.shape},y_train size is {y_train.shape}')

img_size=128

from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import *

"""**Implementing using Dense U-net 65**"""

input_size=(img_size,img_size,1)
inputs = Input(input_size)
conv_1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
conv_1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv_1)
pool_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)
conv_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool_1)
conv_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv_2)
pool_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)
drop_1 = Dropout(0.3)(conv_2)
conv_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool_2)
conv_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv_3)
pool_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)

up_3 = Conv2D(258, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(pool_2))
merge_1 = concatenate([drop_1,up_3], axis = 3)
conv_6 = Conv2D(258, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge_1)
conv_6 = Conv2D(258, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv_6)

up_7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv_6))

conv_7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(up_7)
conv_7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv_7)

conv_10 = Conv2D(1, 1, activation = 'sigmoid')(conv_7)

model2 = Model(inputs=inputs, outputs = conv_10)

model2.compile(optimizer='sgd', loss = 'binary_crossentropy')
      
model2.summary()

history_2=model2.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=2,batch_size=64)

result_2=model2.evaluate(X_test,y_test)
result_2

import matplotlib.pyplot as plt

plt.figure(figsize=[8,6])
plt.plot(history_2.history['loss'],'r',linewidth=2.0)
plt.plot(history_2.history['val_loss'],'b',linewidth=2.0)
plt.legend(['Training loss', 'Validation loss'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('loss',fontsize=16)
plt.title('val loss',fontsize=16)

"""**implementing using Dense U-net++**"""

input_size=(img_size,img_size,1)
inputs = Input(input_size)
conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
drop4 = Dropout(0.5)(conv4)
pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
drop5 = Dropout(0.5)(conv5)

up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
merge6 = concatenate([drop4,up6], axis = 3)
conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
merge7 = concatenate([conv3,up7], axis = 3)
conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
merge8 = concatenate([conv2,up8], axis = 3)
conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
merge9 = concatenate([conv1,up9], axis = 3)
conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

model = Model(inputs=inputs, outputs = conv10)

model.compile(optimizer='adam', loss = 'binary_crossentropy')
      
model.summary()

model_checkpoint = ModelCheckpoint('unet_lits.hdf5', monitor='loss',verbose=1, save_best_only=True,mode='auto')
learning_rate=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.0001)
                                           
                                           
                                           
cb_early_stop=EarlyStopping(monitor = 'val_loss', patience = 3)
# logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
# tensorboard_callback = TensorBoard(logdir, histogram_freq=1)

history=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=2,callbacks=[learning_rate,model_checkpoint],batch_size=64)

import matplotlib.pyplot as plt

plt.figure(figsize=[8,6])
plt.plot(history.history['loss'],'r',linewidth=2.0)
plt.plot(history.history['val_loss'],'b',linewidth=2.0)
plt.legend(['Training loss', 'Validation loss'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('loss',fontsize=16)
plt.title('val loss',fontsize=16)

from tensorflow.keras.utils import plot_model
plot_model(model,to_file='model_.png',show_shapes=True, show_layer_names=True)
from IPython.display import Image
Image(retina=True, filename='model_.png')

model.evaluate(X_test,y_test)

decoded_imgs = model.predict(X_test)

import random
n = 10
plt.figure(figsize=(40, 8))
for i in range(1,11):
    # Display original
    l=random.randint(1,len(X_test)-1)
    ax = plt.subplot(2, n, i)
    plt.imshow(X_test[l].reshape(img_size, img_size))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Display reconstruction
    ax = plt.subplot(2, n, i + n)
    plt.imshow(decoded_imgs[l].reshape(img_size, img_size))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()



from google.colab import drive
drive.mount('/content/drive')

!cp /content/drive/MyDrive/unet_lits.hdf5 /content/

ls -lrth

model=load_model('unet_lits.hdf5')
model.summary()
decoded_imgs=model.predict(X_test)
# result

plt.figure(figsize=(30,30))
plt.subplot(5,5,1)
# image_0 = cv2.imread()  
# image_0 = cv.cvtColor(image_0, cv.COLOR_BGR2RGB)
n=15
plt.title("Actual Image",fontsize=20)
plt.imshow(X_test[n].reshape(img_size,img_size))
# image_0 = cv.resize(image_0,(500,500))
# image_0 = image_0.reshape(1,500,500,3)
# prediction_0 = TransferLearningModel.predict(image_0)
# pred_0 = prediction_0.reshape(500,500,3)
# pred_0 = cv.resize(pred_0,(710,470))
# pred_0=cv2.imread()
plt.subplot(5,5,1+1)
plt.title("Segmented Image",fontsize=20)
plt.imshow(decoded_imgs[n].reshape(img_size,img_size))
plt.subplot(5,5,1+2)
# img_g0 = cv2.imread()  
# img_g0 = cv.cvtColor(img_g0, cv.COLOR_BGR2RGB)
plt.title("Ground Truth",fontsize=20)
plt.imshow(y_test[n].reshape(img_size,img_size))

result=model.evaluate(X_test,y_test)
result

"""Creating dataframe for results"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df1=pd.DataFrame(data=[[result,result_2]],columns=['U-net++','U-net 65'])
# df.head()
plt.title('Comparision of models loss')
plt.xlabel('models')
plt.ylabel('loss')
sns.barplot(data=df1)
plt.show()

df1.head()

